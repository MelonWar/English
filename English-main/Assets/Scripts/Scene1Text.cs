using JetBrains.Annotations;
using System.Collections;
using System.Collections.Generic;
using System.Linq;
using TMPro;
using UnityEngine;
using UnityEngine.UI;

public class Scene1Text : MonoBehaviour
{
    [SerializeField] Canvas canvas;
    TextMeshProUGUI text;
    [SerializeField] List<Button> buttonList;
    List<string> texts = new List<string>();
    IEnumerator coroutine;
    [SerializeField] PauseMenu menuPause;
    int dernierIndex = 19;
    // Start is called before the first frame update
    void Start()
    {
        foreach (var button in buttonList)
        {
            button.enabled = false;
            button.interactable = false;
            button.gameObject.SetActive(false);
        }
        text = canvas.GetComponentInChildren<TextMeshProUGUI>();
        canvas.enabled = false;
        texts.Add("Le sujet de l’intelligence artificielle est sur toutes les lèvres durant ces derniers mois. Cette nouvelle technologie révolutionnaire a le potentiel de changer la face du monde, pour le meilleur et pour le pire. Mais que savez-vous réellement sur l’intelligence artificielle? Ces algorithmes sont si complexes que même leurs développeurs les considèrent parfois comme des «boîtes noires» dont il est impossible de comprendre le fonctionnement réel et, par conséquent, dont il est impossible de prévoir l’évolution. C’est pour cette raison que plusieurs experts dans le domaine ont signé une lettre ouverte demandant l’arrêt du développement de la technologie pour 6 mois, le temps de s’assurer de la sécurité de ces machines. Plusieurs questions troublantes y sont posées telles que : «Devrions-nous développer des esprits non-humains qui pourraient éventuellement nous surpasser en nombre et en intelligence, nous rendre inutiles et nous remplacer?");
        texts.Add("Bien sûr, il est impossible d’arrêter le progrès. Cependant, le but de cette lettre était d’ouvrir la discussion sur les risques relatifs à l’intelligence artificielle et les enjeux éthiques liés à cette technologie. Par contre, il est difficile pour un profane de suivre le débat sans les connaissances techniques requises pour comprendre les subtilités de ces machines. C’est pourquoi nous avons décidé de créer un jeu dans lequel vous pourrez découvrir par vous-même différents aspects de l’intelligence artificielle ainsi que plusieurs enjeux éthiques importants qui y sont liés. À la fin de cette aventure, vous serez en mesure de participer à la discussion importante concernant le futur de cette technologie qui nous affectera tous. Alors, êtes-vous prêt à vous lancer au cœur de ce monde tout aussi merveilleux qu’effrayant?\r\n");
        texts.Add("Artificial intelligence has been a hot topic these last few months. This new groundbreaking technology  has the potential to change the world for better or for worse. But, what do you really know about artificial intelligence? These algorithms are so complex that even the developers making that technology consider them like “black boxes” that are incomprehensible, thus having an unpredictable outcome. It's for this reason that a lot of experts in the domain signed an open letter asking to cease the development of that technology for six months, in order to assure the security of these machines. A lot of troubling questions are asked in the letter like : “Should we develop nonhuman minds that might eventually outnumber, outsmart, obsolete and replace us?”");
        texts.Add("Of course, progress is unstoppable. However, this letter’s purpose was to open a conversation over the risks related to artificial intelligence and the ethical issues linked to this technology. On the other hand, it is difficult for the uninitiated to follow the debate without the required technical knowledge to grasp the intricacy of these machines. That is the main reason why we decided to create a game in which you can discover by yourself different aspects of artificial intelligence as well as several important ethical issues related to it. By the end of this adventure, you will be able to participate in more important discussions regarding this technology’s future, a technology that will affect us all. So, are you ready to dive into this wonderfully frightening world?\r\n");

        //Texte 1
        texts.Add("<u><b>Artificial intelligence</b></u> or AI, as it is often called, is a term widely used and for a variety of computer <u><b>programs</u></b>. But not all computer programs are “intelligent”. When we refer to AI, we usually refer to an <u><b>algorithm</u></b> that is able to make decisions based on a series of <u><b>inputs</u></b>. Here is a definition by IBM : “At its simplest form, artificial intelligence is a field, which combines computer science and robust datasets, to enable problem-solving.”[3] Artificial intelligence softwares are designed to think and act like humans or, ideally, think and act rationally.\r\n");
        texts.Add("There are different types of such algorithms. Most of them are <b><u>machine learning</b></u> algorithms. We use the term “learning”, because these algorithms are <b><u>optimized</b></u> over a great number of <b><u>iterations</b></u> through a data set. To be more technical, “they consist of three parts: a decision process, an <b><u>error function</b></u> and a model <b><u>optimization</b></u> process.”[5] Machine learning algorithms can be linear regression models, logistic regression or <b><u>decision trees</b></u>, which are all types of algorithms that can be described as big mathematical <b><u>functions</b></u>.\r\n");
        texts.Add("Another type of machine learning algorithm is <b><u>artificial neural networks</b></u>. Another term to describe them is <b><u>deep learning</b></u> algorithms. These models try to mimic the human brain, which is composed of billions of <b><u>neurons</b></u> that are linked in a certain way that allows intelligence to emerge.\r\n");
        texts.Add("It is important to understand that most problems do not require complex neural networks to be solved. But for some problems, it is impossible to “hard code” all the possibilities to ensure that the program always works. For example, imagine we wanted to make a program which tells if a certain image contains a cat. We could try to make the program analyze certain characteristics of cats like does it have four legs, two ears, fur, etc. But if we code a program with these exact instructions, it would say that the image contains a cat if we present an image of a dog, because a dog also has the same characteristics.\r\n");
        texts.Add("That is where a neural network becomes a great idea because it can handle new and unorganized <b><u>data</b></u> with greater accuracy than “hard coded” programs. A biological brain can make the difference between a dog and a cat because it has seen many examples of both and is able to extrapolate to new situations. Neural networks, trained with enough data, are able to do the same.");
        texts.Add("Move to the room on your right to discover what a neural network might look like.\r\n");
        //Texte 2
        texts.Add("Now that you have understood the bases of neural networks, you might wonder how developers manage to arrange the weight and bias of each neuron in order to achieve the desired goal, considering that the biggest networks can contain up to hundreds of neurons. The answer is that they don’t do it themselves. In fact, it would be nearly impossible to figure out the required combination of weights and biases in a big network due to how abstract and complex it is.\r\n");
        texts.Add("In practice, deep neural networks learn by themselves. Developers train neural networks on large data sets. The idea is quite simple : you feed the algorithm with an <b><u>input</b></u> and let it process it to give an <b><u>output</b></u>. For the <b><u>training data</b></u>, there is an expected output associated with every input. The output of the algorithm is then compared to the expected output in a loss function, which essentially calculates how much the neural network <b><u>prediction</b></u> is wrong compared to the expected answer. Then, based on the result of the loss function, there is a combination of complex techniques, called <b><u>backpropagation</b></u> and gradient descent, which slightly modify the weights and biases of the network in order to improve the accuracy of the network in future <b><u>iterations</b></u>.\r\n");
        texts.Add("The training process of a neural network can be very long and requires enormous quantities of data. That is why we often hear that data is the new oil. Another thing to take into consideration is that the data set on which the AI has been trained on will greatly influence its outputs. For example, a facial recognition algorithm which was trained mostly on white Americans had difficulties detecting faces which were not similar to those in the training data set, like Black people. Often, what takes the biggest amount of time when developing a new AI system is gathering enough data, labeling it correctly and making sure that this data covers all the possible situations the AI might need to handle.\r\n");
        texts.Add("Another thing you might have realized when playing with the networks in the previous rooms is how complex these algorithms can become. With only 3 layers and a low number of neurons, it can be really hard to understand how each input affects the next layer and, in turn, the output. With more layers and more neurons, it is practically impossible to understand the network in its entirety. This is why neural networks are often called “<b><u>black boxes</b></u>”. The developers know what comes into the network but have no idea how it is processed and how the network arrives at a certain output. For example, if you feed an image recognition algorithm an image of a cat and it says it is a bus, it is hard to know what went wrong. \r\n");
        texts.Add("In some cases, it is not really important to know how the algorithm arrived at a certain output, but in other cases, it may be necessary to use other algorithms which are way easier to interpret like <b><u>decision trees</b></u>. Here is a great example of such a situation : “a lot of banks don’t use neural networks to predict whether a person is creditworthy — they need to explain to their customers why they didn’t get the loan, otherwise the person may feel unfairly treated.”[4] In the long run, we might not always want to take advice from artificial neural networks, because we have no idea how they came up with those advices and it is important to know the reflexion process before taking an important decision. ");
        texts.Add("At the same time, it is understandable that artificial neural networks are hard to pierce through, because they try to mimic biological neural networks which we still have minimal knowledge about. For example, when you come up with an idea, it is impossible to pinpoint what neurons in your brain fired at which moments to create this idea. For humans, although, people are usually able to explain their reasoning to others when asked to do so. This is something scientists are still working on for AI systems.\r\n");
        texts.Add("All things considered, neural networks have some big flaws. They act like a “black box”, they require enormous quantities of data to train on, they usually take a big amount of time to develop and they are computationally expensive. But, at the same time, they have a lot of advantages that make them a great solution to many problems. In fact, their ability to handle unorganized data with great accuracy and think abstractly make them essential for some challenging situations.");
        texts.Add("AI systems are used in a variety of cases today. Some well-known examples are speech recognition, customer service <b><u>chatbots</b></u>, computer vision, recommendation engines and automated stock trading. They are also used in <b><u>natural language</b></u> processing, which we will explore in detail later on your journey. In all these domains, the input is never truly the same, but a neural network can generalize a situation and arrive at the right conclusion.");
        texts.Add("As you continue your journey through this world, you will encounter many ethical problems that arise from the use of AI algorithms. Sometimes, those problems are directly linked to the very nature of neural networks, so keep their structure in mind while you advance to the next chapter.");

        texts.Add("It’s always been a dream of humans to create a machine that could think like them or even surpass human intelligence. Going as far back as the ancient Greeks, there have always been people who wanted to achieve that dream. But, for the longest part of history, it stayed a dream as there were no concrete ways to make it happen.\n");
        texts.Add("It all changed around the year 1950 when the first computers were created. It had already been thought by some philosophers like Aristotle, Descartes and Leibniz that human thoughts could be described as a mechanical process. If you think about it, this is really a key concept in artificial intelligence. If the biological brain of humans works exactly as a machine, it could be reproduced.");
        texts.Add("This is the idea that drove famous mathematician and father of computer science Alan Turing to write the paper Computing Machinery and Intelligence which explored the possibility that if humans use available information to solve problems, computers could do the same.[9] Although, Turing was limited by the fact that computers were still in their early ages, which meant they were quite expensive and light years away from the processing power they have today.\n");
        texts.Add("That being said, his ideas lived long after his death in 1954. In the decades that followed, computers gained a lot of speed and could store a lot more information. This meant that AI flourished and there was a lot of hope about its future. Some people even proposed that AI could surpass human intelligence by the year 2001 or before. In the 1980’s, AI received a lot of funding and there was a lot of hype surrounding it. But, as always, some obstacles got in the way and people realized it could be a lot harder than imagined. The funding dropped in the 90’s, but development of AI thrived nevertheless.\n");
        texts.Add("A big milestone was passed in 1997, when IBM’s computer program <b><u>Deep Blue</b></u> defeated the chess world champion of the time Garry Kasparov. This was a big event and a highly symbolic one because it was the first time an artificial intelligence surpassed human capacities in a game which was recognized to be complex and require a lot of thinking. And this was just the beginning of chess computers. These days, the best chess computers are so far ahead of humans that even if you took all the best chess players in the world and gave them the amount of time they wanted they still wouldn’t be able to defeat the machine.\n");
        texts.Add("A similar milestone was passed in 2016 when Deep Mind’s AlphaGo defeated one of the greatest Go player of all time, Lee Sedol. The reason this was a big deal is that Go is much more complex than chess and it was thought that computers could never surpass humans in that game.\n");
        texts.Add("The main reason AI is able to progress year after year is that processing power keeps on improving year after year. As you should know by now, AI requires a lot of data and processing power. The more it has, the better it performs. The never ending rise in computing power combined with advancement in algorithmic techniques lead to many breakthroughs since the year 2000. We now have speech recognition softwares and <b><u>prediction</b></u> algorithms for things going from the weather to a person's preferences in movies.\n");
        texts.Add("Although, there has never been in human history more hype about AI than since 2020. This is approximately when <b><u>generative AI</b></u> became good enough to be used for a variety of tasks and by many businesses. Generative AI could be described as any algorithm that can produce new content based on a <b><u>prompt</b></u>. This includes <b><u>chatbots</b></u> and image generating algorithms. The most popular example at the time is chat <b><u>GPT</b></u>.\n");
        texts.Add("The hype around artificial intelligence is shown in the public’s interest in the matter but is also shown by the capital investment on its development. In 2021, a staggering sum of around 72 billion U.S. dollars was invested in AI.[11] This makes the field of AI a highly profitable one, which is great, because it drives a lot of innovation, but at the same time, it could influence some people to value money over safety.\n");
        texts.Add("At this time, AI development is primarily fueled by big tech companies like Microsoft, Alphabet (Google), NVIDIA, Tesla and IBM. There are also a bunch of <b><u>startups</b></u> in the field, but some of them end up being bought by these big companies. As it was mentioned previously, there is a lot of money to make in the field of artificial intelligence and this kind of leads to an unhealthy race between these companies. Because being the first to develop a certain technology often leads to a dominant advantage in the market, these enterprises are willing to go to great lengths to speed up their research and development.\n    ");
        texts.Add("For any average technology, it wouldn’t be a big deal. The issue with AI is that it has the potential to change the world, for better or worse, so it is certainly not something we want to rush as a species. Going too fast in its development could lead to breaches in its security or harm to humans in general.\n");
        texts.Add("A great example to illustrate the effects of the AI race is the case of Open AI. When it was first created in 2015, it was a non-profit which had the declared goal to ensure that <b><u>artificial general intelligence</b></u>—AI systems that are generally smarter than humans—benefits all of humanity. It had hopes to improve healthcare, help to solve global warming and improve education. In 2019, the company transferred their model from a non-profit to a \"capped\" for-profit, with a profit capped at 100 times any investment. This had the goal to attract investors in order to afford the best AI researchers, because those are really expensive and most of them would prefer to work at a profitable company like Google that would be able to pay them more. Open AI then struck a 1 billion dollar deal with Microsoft which allowed the giant to use their technologies.\n");
        texts.Add("Fast forward to today and Open AI is now worth 29 billion U.S dollars. It received many more investments and its relationship with Microsoft is as strong as ever. It developed Chat GPT and <b><u>DALL-E</b></u> , an image generating software, two great successes which were then implemented in Microsoft tools.");
        texts.Add("At its beginning, Open AI was open source (hence the “Open” in the name), meaning it shared its progress and discoveries with the public, but, as time went by, it became progressively more closed source and profit-driven. There is one good reason they hide some of their code, which is that it could be used by some unscrupulous people with bad intentions, but in general, it is more due to the tendency of their shift towards the corporate world rather than their “for the greater good” origin.\n");
        texts.Add("This isn’t to say that Open AI has bad intentions; it still has a noble mission statement and it’s reasonable to say that it will develop AI in an ethical way for the years to come. If we think about Chat GPT, there are many ways in which it could have been dangerous, but the developers made sure to control what the chatbot could produce so that it is acceptable before launching it and making it available to the public. But, money still drives the world at this moment of time and non-profits with noble mission statements are often influenced by the corporate world. In AI, this means that most initiatives towards safety and caution are overruled by the precipitation to develop the most recent technology.\n");
        texts.Add("To add to the dangerous nature of this race, we have to remember that artificial neural networks are chaotic, meaning it is almost impossible to predict their evolution. This is to say that if general artificial intelligence is developed, that is an AI that could compare to humans in most cognitive tasks, it would be extremely hard to tell where it would lead us.\n");
        
        texts.Add("<u><b>Generative AI</u></b> is a name given to AI systems that produce new material. This material can be written, images or anything else. For example, some softwares can create a whole new image with a simple <u><b>prompt</u></b>, and a lot of the time these images are really representative of the prompt given and quite impressive. A popular type of generative AI these days is <u><b>large language models</u></b>, or LLMs as they are often called. Large language models generate texts in natural language when given a certain prompt. Their role is to process <u><b>natural language</u></b> and give a certain output depending on what they have been designed and <u><b>optimized</u></b> for. A well-known example is Chat-GPT, a chatbot that can generate new stories, give recipes ideas, answer many questions, create some code scripts for many purposes and much more. \n");
        texts.Add("But large language models are not limited to this broad chatbot model. In fact, we have used many variants of them for quite some time now. Think about text correctors, automatic <u><b>completion</u></b> suggestions like the ones you get when writing emails, google searches or even code, or even word suggestions when you write on a mobile device (the three words above your digital keyboard). Those are all language models because they process natural language, analyze it and output something sometimes as simple as a single word. To summarize, large language models can be used for sentence completion, question answering, translation, summarization and more. The technology behind those systems is quite complicated, and we won’t dive into all the details, but here is what you need to know.\n");
        texts.Add("At their core, those algorithms are all <u><b>pattern recognition</u></b> and <u><b>prediction</u></b> algorithms. The most basic prediction algorithm would be one that has access to a <u><b>database</u></b> containing the most frequent word after the last 5 words, for example, and that would output this word. But this algorithm would be limited in its capacity to generate new content and would quite often produce incoherent answers. But for completion language models, it is often enough. For chatbots, the prediction is done by an artificial neuron network.\n");
        texts.Add("The first step of development is to train the network on large quantities of data. The collection of texts and/or audio on which the AI was trained is called the <u><b>corpus</u></b>, and it will greatly influence how the LLM behaves. A LLM trained on law documents will likely produce long and complicated sentences with law terminology, while one trained on Shakespeare’s work will be more poetic. In the worst scenarios, an AI that has been trained on racist and sexist texts can in turn output racist and sexist sentences. That is what happened to a chatbot trained on Twitter users’ input, Tay, but you will learn about him more later. The selection of the corpus is a crucial step in a LLM development as it will determine what the algorithm outputs. For the biggest of them, like the infamous chat GPT, their developers keep their corpus a secret, but we can assume it has gone through most parts of the internets, or at least sites like wikipedia, public forums and code documents from sites related to programming. By going through these immense quantities of data, the LLM is able to learn grammar, basic facts about the world, reasoning abilities, but it also picks up the biases present in the data.\n");
        texts.Add("The neural network is then optimized to output a satisfying answer. There are many ways to do this. The first step often consists of just <u><b>feeding</u></b> the algorithm with prompts and their desired answers, written by a human. For the second step, the algorithm generates around 4 answers to a given prompt and a human ranks them for best to worst. The neural network is then optimized according to this ranking. In the third step, the LLM generates an answer to many prompts and calculates with another algorithm a reward to improve the neural network.\n");
        texts.Add("It is important to understand that LLMs are mostly optimized to produce satisfying answers and have no notion of truth, which means they will often create information from sources that don’t really exist if it means their answer is more complete and satisfying. These algorithms are not conscious, they only predict the most likely word following a series of words, which means they have no conscious idea of what they are saying and don’t deal with complex problems in the same way humans do. That is why models like chat GPT have a little warning below their prompt entry place that says : “ChatGPT can make mistakes. Consider checking important information.”\n");
        texts.Add("Other parameters can also influence the behavior of a LLM. An interesting one is temperature Temperature can be thought of as the “randomness factor” of a LLM. When a LLM analyzes a sequence of words, it can rank the probability of each word that could come next. For example, for the half sentence “The dog is”, the network might predict that the word “cute” has 60% chance of being right, “aggressive” 30% and “hairy” 10%. If the temperature is low, the LLM will always choose the most likely word. If the temperature is high, it will choose at random between the most probable words. A low temperature generally means the sentences are going to be more coherent and logical, but also means the output will likely be close to what has already been written and not so new. A high temperature, on the other hand, allows the LLM to generate more creative responses, but also presents a greater risk of incoherent responses and false information. LLMs’ developers try to strike a balance between the two extremes depending on their goal. Temperature also explains why chat GPT can generate different answers for the same prompt and also regenerate a new answer if asked to do so.\n  ");
        
        texts.Add("Language models AI are quite a fascinating phenomenon. Some AIs seem like genies in a bottle ready to fulfill the wishes of every wanderer asking questions about everything and anything going on in this world. Whether it be a student asking questions for an essay or a paper to write, a programmer asking to fix error codes or even philosophical intrigues like “What is God” are situations where this type of AI holds answers and certainty. Well, it is unfortunate, simply because it's not true. The reality of the situation is that they do not always possess correct information as they are biased by the data that they feed on. Indeed, language models AI like chat gpt are biased and do not always deliver objective sources of information.In fact, in some situations that really happened, the information or content given by an AI turned out to be something extremely unhelpful and quite bad.  We can see that through many iterations of AI like Tay, the twitter (now X) language model and how the data collecting process works. \n");
        texts.Add("This technology can be quite frightening. As seen in the previous texts Generative AI and LLMs create all sorts of content. These technologies that were released not so long ago evolve at an exponential rate and don’t seem to be stopping anytime soon. The best and most known example of our time is the infamous chat gpt who has the capacity to mimic (not perfectly) an engineering student in an exam if math is not implied in the question(quote d’un pdf). This technology, being an LLM, is the second AI that passed the <u><b>Turing test</u></b> and is now progressively developing to a point where humans can mistake chat gpt’s answer for that of a living being. \n");
        texts.Add("To be brief, this technology feeds on data given by us and processes it to give an information that reaches the possibility of being a logical answer. To put it more bluntly, the professional Chris Phipps who works in the AI field describes these LLMs as a “very good prediction machine. ”(quote de EBSCO). Now that you know what an artificial neural network is, think about it this way: a massive neural network with tons of neurons with the goal to predict as precisely as possible what the answer to a prompt would be. This means the algorithms and the process of LLMs don’t focus on giving perfect information, but focus more on sounding and acting human. For example, and this is a story based on real experiences, when a student didn’t know what to write for a written production asked chat gpt to give a synopsis of the book in question, The AI gave a story similar to what you can find on the internet about the book. Nevertheless, when asked more specific questions or quotes, the AI started inventing characters and lines that weren’t remotely similar to the narration of the book. Indeed, the algorithm knew what the story was because of the data it had, but when confronted with more specific information, he resorted to predicting what the answers were. \n");
        texts.Add("The craziest part about these language models is that, depending on the situation, they can be very biased in their answers. Not only giving subjective information, but also discriminatory and touchy opinions. Indeed, for a LLM to function, it needs to learn from all sources of data coming from every type of content possible like books, documentaries etc. Nothing guarantees that the sources contain unbiased opinions or that the algorithm of the AI will arrive with a heavily biased conclusion  when learning from the data. An example given by DeepChecks, a company that evaluates LLMs, really puts it in concrete perspective : \n");
        texts.Add(" “Let’s consider an example. Suppose an LLM is trained on a dataset where most references to doctors are male and nurses are female. In that case, the model might learn to associate the doctor profession with men and nursing with women. This is a form of gender bias, and it can lead to the model generating biased outputs, even when the input doesn’t specify a gender.”\n");
        texts.Add("So yes, an AI can totally deliver misinterpreted information and, with the help of biased <u><b>training data</u></b>, can encourage and back up harmful stereotypes that goes beyond only gender. These types of biases can go to racism and prejudice that lead to xenophobia or any type of harmful mindset. This is a huge ethical problem for LLM developing companies as this could create AIs with harmful thinking that could teach these doctrines to people.");
        texts.Add("Continuing further, there are real examples of AI going wrong in the worst of ways. This is the story of Tay, the Twitter (now X) chat bot that became extremely problematic in less than 24 hours. The year is 2016 and microsoft announced the launch of a new revolutionary project: Tay, the AI that would react to human interaction based on social media in order to develop and get smarter. What Microsoft wouldn’t expect is the AI going wrong and transforming into, not a well developed bot, but a racist, homophobic being. \n");
        texts.Add("In fact, Tay tweeted around 96 000 tweets in her less than 24 hours existence. In these specific tweets, it smoothly progressed from “can i just say that im stoked to meet u? humans are super cool!” to “I fucking hate feminists and they should all die and burn in hell.” or “Hitler was right I hate the jews.” This intelligence went rogue in such a small lapse of time and we can only ask ourselves why? Well it's simple, but also really complex. Tay acted the way she did only because of one important factor and that would be us. The data she got to develop herself was learning from the tweets and interactions from humans on the platform. All those comments whether they are homophobic, misogynist or racist all stem from us. The majority of what she said can be attributed to tweets from other people, a lot like a child who speaks a certain way because of her parents. But also, her opinions seemed to not be cohesive at all. For example, Tay did say comments against feminism, but also tweeted statements like “i love feminism now”. She also responded to questions without really copying tweets and came to some really weird conclusions. A user asked “Is Ricky Gervais an Atheist” and she simply responded that “ricky gervais learned totalitarianism from adolf hitler, the inventor of atheism.”\n");
        texts.Add("This LLM is the perfect example of a heavily biased bot. Microsoft released an AI in the most subjective environment there is being social media, a place full of contradictions, conflicts and also… <u><b>trolls</u></b>. People don’t always have the best of intentions on the internet and they had a lot of fun playing around with Tay to make her the most controversial AI there is. If bad people get their hands on such algorithms, it becomes simple to create an ill-intentioned AI. This situation can bring us to important questions like “Are AIs ready to interact with human beings without going berserk?” and “Are companies doing the best they can to optimize AI learning algorithms?”\n\n");
        texts.Add("In the end, LLMs do the best they can to revolutionize the field of artificial intelligence and this subject is heavily worked on. However, what is most important is the trust we give these kinds of technologies. One thing is certain, AI does represent a powerful tool that embodies a new path to our future, but we also can’t forget they can represent a certain danger in terms of false information and bias. The most we can do as people who use this technology is to take every ounce of information and analyze it with critical thinking and be sure that the information is indeed useful or correct. \n");
        
        texts.Add("<u><b>Deepfakes</u></b> grew way too fast; no one was able to see them coming. They arrived as fun toys but left as purely destructive tools. Nowadays, you’re far better betting that a video is AI generated than the opposite. There is no more faith for that media, if only we could have prevented that. If you are reading this, you might be curious about how we got here, so let me tell you about the rise of deepfakes.\n");
        texts.Add("Generative Adversarial Networks, A.K.A. GANs, are what made deepfakes possible. You most likely are asking yourself about what a GAN may be, so let me explain. It’s a computer process, requiring 2 AIs, a forger and a detective. The forger is the one creating the image, while the detective uses its massive database to tell the forger every single mistake it made, and the cycle is repeated over and over until a perfect match is produced. As it might be expected, this process is extremely heavy and requires a lot of resources to create a near impeccable clone.");
        texts.Add("Well we used to need a huge amount of data to create deepfakes, but with the rise of multiple organizations like DeepVodoo focusing on the subject, this technology became more and more accessible, giving the ability to apply other people’s faces on our own with a snap of a finger, just like a simple filter. It was mainly used in movies or videos, trying to use other actors’ faces without needing them to be the ones acting. It was a simple and fun technology, until people realized how powerful it could be.\n");
        texts.Add("You might start to be worried about the technology, but don’t worry, you aren’t alone. Governments were the first to get concerned. A technology that can mix together facts and fiction can create quite the chaos in a society. Recorded media would lose its credibility, since it would be easy for the public to forge fake evidence. They predicted that by 2026, most online content will have been artificially generated. Well, they weren’t too far off, unfortunately.\n");
        texts.Add("The scariest of all is how it was used in cybercrime. How celebrities will be shown presenting some fake product or a sneaky <u><b>cryptocrime</u></b>, and people will simply buy into that, because why wouldn’t they trust these famous people they all love and cherish so much? Or even how criminals impersonated people in power to steal money or personal data.\n");
        texts.Add("What, who will you trust? If a major part of a group are liars, they might as well all be, but is it a reason to all throw them in the same boat? Is it worth dismissing all of them to protect ourselves from the real liars? That was the big dilemma that the authorities had to face. One thing was sure, they had to give themself a fighting chance, but how do you fight a tool that is so widely spread that a 15 minutes tutorial online will teach anyone how to use it? Even written text can’t be reliably detected as virtually made, so is there a way to solve that crisis?\n");
        texts.Add("They tried to first understand this technology,but they were too slow. Deepfakes were growing faster than they could catch up, so they tried to regulate it by, for example, forcing deepfakes to be marked as such, so that they could be differentiated from non-AI-generated media, but how would they enforce that law? They needed help, help from the actual experts. \n\n");
    }

    // Update is called once per frame
    void Update()
    {
        if (Input.GetKeyDown(KeyCode.Escape))
        {
            canvas.enabled = false;
            StopAllCoroutines();
        }
    }
    public void ShowLastText()
    {
        dernierIndex--;
        ShowText(dernierIndex % texts.Count);
    }
    public void ShowText()
    {
        ShowText(dernierIndex % texts.Count);
        dernierIndex++;
    }
    public void ShowText(int index)
    {
        dernierIndex = index;
        StopAllCoroutines();
        canvas.enabled = true;
        text.text = "";
        foreach (var button in buttonList)
        {
            button.enabled = false;
            button.interactable = false;
            button.gameObject.SetActive(false);
        }
        switch (index)
        {
            case 4:
                buttonList.ElementAt(0).enabled = true;
                buttonList.ElementAt(0).interactable = true;
                buttonList.ElementAt(0).gameObject.SetActive(true);
                buttonList.ElementAt(0).GetComponentInChildren<Text>().text = "Check \"Artificial Intelligence\" in Glossary";
                buttonList.ElementAt(0).onClick.AddListener(menuPause.OpenPage1);
                buttonList.ElementAt(1).enabled = true;
                buttonList.ElementAt(1).interactable = true;
                buttonList.ElementAt(1).gameObject.SetActive(true);
                buttonList.ElementAt(1).GetComponentInChildren<Text>().text = "Check \"Programs\" in Glossary";
                buttonList.ElementAt(1).onClick.AddListener(menuPause.OpenPage4);
                buttonList.ElementAt(2).enabled = true;
                buttonList.ElementAt(2).interactable = true;
                buttonList.ElementAt(2).gameObject.SetActive(true);
                buttonList.ElementAt(2).GetComponentInChildren<Text>().text = "Check \"Algorythm\" in Glossary";
                buttonList.ElementAt(2).onClick.AddListener(menuPause.OpenPage1);
                buttonList.ElementAt(3).enabled = true;
                buttonList.ElementAt(3).interactable = true;
                buttonList.ElementAt(3).gameObject.SetActive(true);
                buttonList.ElementAt(3).GetComponentInChildren<Text>().text = "Check \"Inputs\" in Glossary";
                buttonList.ElementAt(3).onClick.AddListener(menuPause.OpenPage4);
                break;

            case 5:
                buttonList.ElementAt(0).enabled = true;
                buttonList.ElementAt(0).interactable = true;
                buttonList.ElementAt(0).gameObject.SetActive(true);
                buttonList.ElementAt(0).GetComponentInChildren<Text>().text = "Check \"Artificial Intelligence\" in Glossary";
                buttonList.ElementAt(0).onClick.AddListener(menuPause.OpenPage1);
                buttonList.ElementAt(1).enabled = true;
                buttonList.ElementAt(1).interactable = true;
                buttonList.ElementAt(1).gameObject.SetActive(true);
                buttonList.ElementAt(1).GetComponentInChildren<Text>().text = "Check \"Programs\" in Glossary";
                buttonList.ElementAt(1).onClick.AddListener(menuPause.OpenPage4);
                buttonList.ElementAt(2).enabled = true;
                buttonList.ElementAt(2).interactable = true;
                buttonList.ElementAt(2).gameObject.SetActive(true);
                buttonList.ElementAt(2).GetComponentInChildren<Text>().text = "Check \"Algorythm\" in Glossary";
                buttonList.ElementAt(2).onClick.AddListener(menuPause.OpenPage1);
                buttonList.ElementAt(3).enabled = true;
                buttonList.ElementAt(3).interactable = true;
                buttonList.ElementAt(3).gameObject.SetActive(true);
                buttonList.ElementAt(3).GetComponentInChildren<Text>().text = "Check \"Inputs\" in Glossary";
                buttonList.ElementAt(3).onClick.AddListener(menuPause.OpenPage4);
                break;

            default:
                break;
        }
        coroutine = WriteText(index);
        StartCoroutine(coroutine);
    }

    IEnumerator WriteText(int index)
    {
        
        foreach (char c in texts[index])
        {
            text.text += c;
            yield return new WaitForSeconds(0.01f);
            
        }


    }
}
